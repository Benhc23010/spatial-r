[["index.html", "A Minimal Introduction to GIS (in R) 1 Overview 1.1 General 1.2 Using this resource 1.3 Module and Project details", " A Minimal Introduction to GIS (in R) Jasper Slingsby 2021-06-02 1 Overview This is a minimal introduction to GIS and handling spatial data in R compiled for the Biological Sciences BSc(Honours) class at the University of Cape Town. 1.1 General The goal is to give you a very brief introduction to Geographic Information Systems (GIS) in general and some familiarity with handling spatial data in R. GIS is a field of research that many people dedicate their entire lives to, yet we only have a week, so this really is a minimalist introduction. I’ll focus on giving you a broad overview and some idea of how to teach yourself (using R). The core outcomes I hope you’ll come away with: Some familiarity with GIS and what it can help you achieve Some familiarity with GIS jargon and technical terms Highlight some of the common problems and pitfalls when using GIS Some familiarity with handling spatial data in R Some hints and resources to help you teach yourself R Some idea of how to help yourself or find help when you inevitably come unstuck… These course notes borrow or paraphrase extensively from Adam Wilson’s GEO 511 Spatial Data Science course, Manny Gimond’s Intro to GIS &amp; Spatial Analysis and the 2020 series of GIS Lecture Lunches by Thomas Slingsby and Nicholas Lindenberg from UCT Library’s GIS Support Unit. Other very valuable resources include: Lovelace et al’s online book Geocomputation with R Ryan Garnett’s cheatsheet for library(sf) All code, images, etc can be found here. I have only used images etc that were made available online under a non-restrictive license (Creative Commons, etc) and have attributed my sources. Content without attribution is my own and shared under the license below. If there is any content you find concerning with regard to licensing, or that you find offensive, please contact me. Any feedback, positive or negative, is welcome! This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License. 1.2 Using this resource I’ve included quite a bit of demonstration R code in Chapter 7. To tun the code you will need: to have working R and RStudio installations - this tutorial may help if needed to install the following R packages (you can copy and run the code): required: install.packages(c(\"tidyverse\", \"sp\", \"rgdal\", \"raster\", \"sf\", \"lwgeom\")) optional, but handy for some visualizations: install.packages(c(\"cowplot\", \"hrbrthemes\", \"knitr\", \"leaflet\", \"htmltools\", \"rosm\", \"ggspatial\", \"rnaturalearth\")) to download the datasets discussed in section 7.1 1.3 Module and Project details Lectures Lectures will be held in the mornings between 10:00 to 12:00 Monday to Thursday (Friday is presentation day - see below). We’ll have 2 or 3 short live online lectures (I’ll aim for &lt;20 min each) with short breaks. You need to attend live (but remotely). The zoom link (see Vula) should stay the same for all lecture sessions. Projects Afternoons are self-study time where you will incrementally develop your own individual GIS project in R and RMarkdown. The project will count 70% of your mark for the module and will be due on Friday the 11th June. You will need to submit a .Rmd file and stitched HTML notebook. The focus of the assignment is essentially setting up a GIS workflow and will be assessed on whether you’ve absorbed the content of the lectures. The topic and datasets used will be up to you. Pro tip: Use this as an opportunity to get a kick start on your Honours projects. If your Honours project doesn’t require GIS then either help a buddy or let your curiosity roam wild! This is a teaching exercise, so it doesn’t even have to be based on biological data, but it would help you to explore some of the data sources suggested below. The project objectives, broken down as daily goals to help you pace yourselves: Day 1: Define a question that requires GIS, the kinds of data you’ll need to address the question, and describe in words what you think you would need to do with the data to get there. You are welcome to use your Honours project for this and use it as an opportunity to get some GIS help! Day 2: Find and describe the datasets you’ll need for your analysis (type, source, how created, etc). Day 3: Describe the GIS workflow you think you’ll need to perform your analysis (in words and/or a figure) and the R functions you think you’ll need to use. Day 4: Begin coding and running the GIS workflow in R. Until the 11th June: Iterate over the previous steps until done! I will be available 2-3PM every afternoon (excluding Friday) as a “help desk” to assist you refine your projects and help troubleshoot issues. Friday (4th June): you’ll do lightning presentations (30% of your mark for the module) on your GIS projects (1 slide, 2 minutes presentation, 1 minute questions). Don’t worry, you won’t lose marks if your projects are not yet complete! We just want to know what you’re doing your project on, what datasets you’re using, and what you plan to do with them. Please add your slide to the Google slide deck and read the instructions there. Some sources of local data to help you get started. Feel free to look for others! If you find good ones, let me know and I’ll add them. SANBI’s “Biodiversity GIS” - https://bgis.sanbi.org/ SANBI’s Botanical Database of South Africa (BODATSA) - http://newposa.sanbi.org/ SAEON’s Data Catalogue (in beta) - http://catalogue.saeon.ac.za/ City of Cape Town’s Open Data Portal - https://odp.capetown.gov.za/ iNaturalist - https://www.inaturalist.org/ (accessible from R - see section 7.7) Google Datasets Search - https://datasetsearch.research.google.com/ Make sure to check the data use policies and make sure you have permission use the datasets!!! "],["intro.html", "2 Why care about GIS?", " 2 Why care about GIS? How lost would you be without Google Maps? Figure 2.1: Screenshot of Google Maps for Cape Town. If we search “Geographic Information Systems OR GIS” in Web of Science, it is clear that the number of papers using GIS has exploded over time! Figure 2.2: The number of papers on Web of Science when searching Geographic Information Systems OR GIS. GIS is especially important in environment and life sciences! Figure 2.3: The number of papers on Web of Science by theme when searching Geographic Information Systems OR GIS. We use it for things like mapping ecosystems and biomes. Figure 2.4: The historical extent of the biomes of South Africa from Mucina, Rutherford, and Others (2006). Or the loss of ecosystems and biomes. Figure 2.5: The remaining extent of the biomes of South Africa from Skowno, Jewitt, and Slingsby (2021). Although the outcomes of GIS analyses are not always maps, e.g. this table from Skowno et al. (2021). But it can also be interactive! Figure 2.6: The Global Forest Watch app. "],["gis-basics.html", "3 GIS basics 3.1 What is GIS? 3.2 How do we do GIS? 3.3 How to get help?", " 3 GIS basics Here we cover the basics of GIS… 3.1 What is GIS? A Geographic Information System is a framework used to create, manage, visualize and analyze data in a spatial context. Most datasets can be assigned a spatial location, either on the earth’s surface or within some constrained area like a sports field, a vegetation survey plot, or even a drawer in your kitchen. While almost any dataset has a spatial context, and can thus be represented in a GIS, the real question is whether it needs to be analyzed in a GIS environment? The answer to this question depends on the purpose of the analysis. Typically, one would use GIS if you were using the spatial information associated with the data to: access data elements (e.g. select data by spatial location or coverage), perform analytical operations (e.g. overlay and merge two datasets to produce a new dataset), or render visualizations (e.g. generate a map). 3.1.1 An example workflow Identifying the list of South Africa’s threatened ecosystems is largely based on analyses done in GIS, using the map of the historical extent of South Africa’s vegetation types and the National Land Cover data (which, incidentally, were largely created using GIS…). Figure 3.1: South Africa’s list of threatened ecosystems depends heavily on GIS… Here’s a simplified breakdown of the steps in the GIS workflow… Figure 3.2: A simplified workflow for assessing threat to South Africa’s ecosystems, highlighting GIS operations (numbered and in italics). There are many many operations and functions within each of the three major operation types (access, analyze, map). There are also many support functions and operations that are common across the operation types. We’ll delve into these later. 3.2 How do we do GIS? There are a large number of software packages for doing GIS. Some are free (often open source), while others require you to pay for a license (i.e. are proprietary). They also vary in what they do (or the combination of things they do). For example, some of the best known desktop GIS applications, which is what your average GIS user is interested in, include: ArcGIS - a proprietary product that works on Windows only (or online). UCT has a site license, which provides a set number of user licenses for UCT postgrads and staff (see section 3.3 for details). Note that ArcGIS is an ESRI product and comes with (or can be upgraded to include) a suite of other (commercial) software components in addition to the desktop application QGIS (“Quantum GIS”) - free and open source software (FOSS) for Windows, Mac or Linux Google Earth - free (for now), but not open source, for Windows, Mac, Linux, or online Figure 3.3: Screenshot of the QGIS Desktop 3.14 graphical user interface (GUI). Desktop GIS applications are typically graphical user interfaces (GUIs) that call on various other geospatial libraries to do the actual data processing (think of these as sets of functions or tools). Some examples of FOSS geospatial libraries are GDAL and GEOS, which are designed to deal with different data models and/or file types. Another one you’ll encounter quite a bit id PROJ, which deals with coordinate reference systems. We can also do GIS by calling the geospatial libraries and other GIS software types directly with various programming languages. While we can use many (or just about any) coding language, there are a few for which the functions and syntax are better developed for the user, including: R Python JavaScript A major advantage of using these general purpose programming languages for your GIS work is that it allows you take advantage of their functions for statistical analyses and presentation etc all in one environment and/or work flow. This also makes it much easier to make your research reproducible. Note that the geospatial libraries and the other GIS softwares that we call are coded in a variety of other languages, such as Java, C/C++, C# or SQL, but these languages are typically less user friendly and/or more difficult to learn. Other “GIS software types” include: spatial databases such as PostGIS, which is free and open source software (FOSS) for Windows, Mac or Linux and great for storing and querying large and complex datasets web mapping such as MapServer or GeoServer I’m sure there are others I haven’t thought of… 3.3 How to get help? UCT has a GIS Support Unit to assist UCT staff and postgraduate researchers with their GIS and spatial data needs. Their primary goal is to help users develop their GIS skills in order to perform sound data capture, geospatial analysis and map production. They can help you with: Troubleshooting, Project Planning, Analysis, Cartographic Design and Data Handling. GIS Training Applying for an ESRI (ArcMAP) Software license. Note that they predominantly work with ESRI and QGIS and don’t provide support for R, etc. That said, many GIS work flow issues are common across platforms, and the support unit really know what they’re doing. They’re also a good source of data if you’re struggling to find what you need, but please do your homework before asking them for data! Lastly… I am not a help desk!!! The goal for this module is to teach you how to help yourself. I’m available to help in the afternoon office hours during this module, but unfortunately, while I would love to, I do not have the time to help you all with your GIS or R issues for the rest of your careers… You can find the answer to any issue you are encountering in an online forum like GIS Stack Exchange. I typically just type my questions (or copy and past error messages) directly into Google. The trick is working out what to ask, and sometimes you need to reword your question a couple of times to find the answer you need. If you’re really getting nowhere, you can even post your question on a forum, although it is unlikely that you’ll ever need to do this… "],["gis-data-models-and-file-formats.html", "4 GIS data models and file formats 4.1 Data models 4.2 Attribute data 4.3 File formats", " 4 GIS data models and file formats 4.1 Data models GIS data typically come in two data model types vector or raster. 4.1.1 Vector data The three basic vector data types are points, lines (also sometimes referred to as polylines or linestrings) and polygons. While they are treated as different data types, you can also consider them to be a nested hierarchy. For example, to make a line you need two or more points, while a polygon requires three or more lines. Figure 4.1: The hierarchical construction of vector data types. From this we can observe the different properties of the data types: a point is a location in space defined by a set of coordinates based on a coordinate reference system (more about these later) a line is two or more points with straight lines connecting them, where each line has a length a polygon is a set of points connected by lines that form a closed shape, which has an area Note that these “data types” are also commonly called feature classes, geometric primitives or geometries. Later we’ll see that you get more complicated “types,” but these are generally combinations of the above: multipoint, multilinestring, multipolygon, geometry collection, etc and are largely just different data classes designed to help with handling data than unique geometries. Vector data models are obviously the best way to represent points and lines. Polygons are usually the best way to represent discrete (categorical) data, especially where they may have complex boundaries. For example: Figure 4.2: Vector (polygon) representation of discrete data; the vegetation types of the Cape Peninsula. Vector data models are less good for representing continuous data (e.g. elevation, see surface temperature, etc). See further down. 4.1.2 Raster data Raster data are essentially data stored in a regular grid of pixels (or cells). Digital images like jpeg or png files are essentially rasters without spatial information. The value of each pixel is a number representing a measured value (e.g. continuous data such as sea surface temperature) or a category (e.g. discrete data such as land cover class). All pixels have a value, even if the value is “No Data.” Rasters are particularly useful for representing continuous data. Figure 4.3: Raster representation of continuous data; a digital elevation model of the Cape Peninsula. Rasters are great for continuous data. If this was a vector plot of the raw data, each pixel would have to be its own polygon and the legend would have a separate entry for each unique value, &gt;60 000 entries!!! That said, you can quite effectively represent continuous values visually with a vector data model if you bin the continuous data (from the raster) into classes, such as one can do with a filled contour plot (see below). This is not ideal for analyses though, as the binning results in data loss. You’ll find that you often need to convert data between vector and raster models for various reasons, and that this usually means some tough decisions need to be made about what is acceptable data loss. We’ll cover that later. Figure 4.4: Vector representation of continuous data; a filled contour plot of a digital elevation model of the Cape Peninsula using 100m contours. Conversely, rasters are usually not that good at representing categorical data. Note that most raster file formats (and GIS software) can only store numeric data, so this plot misleadingly represents the vegetation types as continuous data. You can label and represent categorical data in rasters in R, but this is usually more effort than its worth and is almost always less effective than using a vector format… A common exception is land use and land cover (LULC) maps, where remotely sensed satellite imagery (raster data) are classified into predefined classes (e.g. agriculture, rock, grassland, etc) based on various criteria or algorithms. Even then, these are difficult to interpret visually with static maps and are best visualized as interactive maps so you can make sense of them by zooming in and panning around. Figure 4.5: Raster representation the discrete data; the vegetation types of the Cape Peninsula. 4.2 Attribute data Attributes are what we know about the objects represented in a layer in addition to their geometry - i.e. each spatial object usually has additional information associated with it. These data are usually stored in an associated Attribute Table. Here are the first few entries of the attribute table for our Cape Peninsula vegetation layer: AREA_HCTR PRMT_MTR veg type Subtype Community geometry 66 6.774255 1596.83494 Beach - FalseBay BEACH Need to Find Out POLYGON ((-46661.36 -380319… 67 14.151168 3886.68578 Beach - FalseBay BEACH Need to Find Out POLYGON ((-47252.77 -380298… 68 8.575597 2154.00714 Beach - FalseBay BEACH Need to Find Out POLYGON ((-49001.26 -380249… 69 0.000001 23.25575 Beach - FalseBay BEACH Need to Find Out POLYGON ((-49353.38 -380223… 70 5.333203 3589.09436 Beach - FalseBay BEACH Need to Find Out POLYGON ((-50030.98 -380131… 71 24.448116 7378.70451 Beach - FalseBay BEACH Need to Find Out POLYGON ((-53108.73 -379998… Note that vector data generally have attribute tables, but they are rare for raster layers, because most raster file formats can store just one attribute per cell (e.g. elevation) and can’t have associated attribute tables. A handy feature of most GIS systems is that they can treat attribute tables like relational database table structures. Additional information can be joined onto your spatial data by joining two tables with a common key field, as one does when joining two tables of non-spatial data. In GIS, this is called an “Attribute Join,” because you have joined the tables by attribute and haven’t used spatial information (also sometimes called a “non-spatial join”). We’ll learn about “spatial joins” later… 4.3 File formats Linked to data models, and attributes, is file formats. Generally, there are separate file formats for vector vs raster data. Usually, we even have separate files for the different types of vectors (points, lines, polygons, etc), but this is changing as new “database” formats evolve. There is a huge variety of GIS file formats, which have proliferated as different software packages have developed their own set of “native” formats. Each of these have different properties in terms of the data they store, whether they can include attribute data, file size and compression, and of course how they actually store (and retrieve) the data. Many of these, like the ESRI formats, are proprietary (i.e. not open source). If you’ve done any GIS before, you’ll be familiar with ESRI shapefiles, which usually include a group of 3 or more files with the same name, but a different file extension. Each file stores different information. The most common ones are: .shp = the main feature geometry .shx = an index file, used for searching etc .dbf = stores the attribute information .prj = stores the coordinate reference system etc = there are many other optional files that may be present depending on the data stored Shapefiles are by far the most common format for vector data. For raster data, the most common format is probably GeoTIFF (.tif) or ASCII (.asc). You can view the lists of most of the file types supported by R (or at least the types supported by the GDAL geospatial library) by running the code rgdal::ogrDrivers() for vector drivers, which gives this output: name long_name write copy isVector AeronavFAA Aeronav FAA FALSE FALSE TRUE AmigoCloud AmigoCloud TRUE FALSE TRUE ARCGEN Arc/Info Generate FALSE FALSE TRUE AVCBin Arc/Info Binary Coverage FALSE FALSE TRUE AVCE00 Arc/Info E00 (ASCII) Coverage FALSE FALSE TRUE BNA Atlas BNA TRUE FALSE TRUE CAD AutoCAD Driver FALSE FALSE TRUE Carto Carto TRUE FALSE TRUE Cloudant Cloudant / CouchDB TRUE FALSE TRUE CouchDB CouchDB / GeoCouch TRUE FALSE TRUE CSV Comma Separated Value (.csv) TRUE FALSE TRUE CSW OGC CSW (Catalog Service for the Web) FALSE FALSE TRUE DGN Microstation DGN TRUE FALSE TRUE DXF AutoCAD DXF TRUE FALSE TRUE EDIGEO French EDIGEO exchange format FALSE FALSE TRUE ElasticSearch Elastic Search TRUE FALSE TRUE ESRI Shapefile ESRI Shapefile TRUE FALSE TRUE Geoconcept Geoconcept TRUE FALSE TRUE GeoJSON GeoJSON TRUE FALSE TRUE Geomedia Geomedia .mdb FALSE FALSE TRUE GeoRSS GeoRSS TRUE FALSE TRUE GFT Google Fusion Tables TRUE FALSE TRUE GML Geography Markup Language (GML) TRUE FALSE TRUE GMLAS Geography Markup Language (GML) driven by application schemas FALSE TRUE TRUE GPKG GeoPackage TRUE TRUE TRUE GPSBabel GPSBabel TRUE FALSE TRUE GPSTrackMaker GPSTrackMaker TRUE FALSE TRUE GPX GPX TRUE FALSE TRUE HTF Hydrographic Transfer Vector FALSE FALSE TRUE HTTP HTTP Fetching Wrapper FALSE FALSE TRUE Idrisi Idrisi Vector (.vct) FALSE FALSE TRUE Interlis 1 Interlis 1 TRUE FALSE TRUE Interlis 2 Interlis 2 TRUE FALSE TRUE JML OpenJUMP JML TRUE FALSE TRUE JP2OpenJPEG JPEG-2000 driver based on OpenJPEG library FALSE TRUE TRUE KML Keyhole Markup Language (KML) TRUE FALSE TRUE LIBKML Keyhole Markup Language (LIBKML) TRUE FALSE TRUE MapInfo File MapInfo File TRUE FALSE TRUE Memory Memory TRUE FALSE TRUE MSSQLSpatial Microsoft SQL Server Spatial Database TRUE FALSE TRUE MySQL MySQL TRUE FALSE TRUE NAS NAS - ALKIS FALSE FALSE TRUE netCDF Network Common Data Format TRUE TRUE TRUE ODBC ODBC TRUE FALSE TRUE ODS Open Document/ LibreOffice / OpenOffice Spreadsheet TRUE FALSE TRUE OGR_DODS OGR_DODS FALSE FALSE TRUE OGR_GMT GMT ASCII Vectors (.gmt) TRUE FALSE TRUE OGR_OGDI OGDI Vectors (VPF, VMAP, DCW) FALSE FALSE TRUE OGR_PDS Planetary Data Systems TABLE FALSE FALSE TRUE OGR_SDTS SDTS FALSE FALSE TRUE OGR_VRT VRT - Virtual Datasource FALSE FALSE TRUE OpenAir OpenAir FALSE FALSE TRUE OpenFileGDB ESRI FileGDB FALSE FALSE TRUE OSM OpenStreetMap XML and PBF FALSE FALSE TRUE PCIDSK PCIDSK Database File TRUE FALSE TRUE PDF Geospatial PDF TRUE TRUE TRUE PGDUMP PostgreSQL SQL dump TRUE FALSE TRUE PGeo ESRI Personal GeoDatabase FALSE FALSE TRUE PLSCENES Planet Labs Scenes API FALSE FALSE TRUE PostgreSQL PostgreSQL/PostGIS TRUE FALSE TRUE REC EPIInfo .REC FALSE FALSE TRUE S57 IHO S-57 (ENC) TRUE FALSE TRUE SEGUKOOA SEG-P1 / UKOOA P1/90 FALSE FALSE TRUE SEGY SEG-Y FALSE FALSE TRUE Selafin Selafin TRUE FALSE TRUE SOSI Norwegian SOSI Standard FALSE FALSE TRUE SQLite SQLite / Spatialite TRUE FALSE TRUE SUA Tim Newport-Peace’s Special Use Airspace Format FALSE FALSE TRUE SVG Scalable Vector Graphics FALSE FALSE TRUE SXF Storage and eXchange Format FALSE FALSE TRUE TIGER U.S. Census TIGER/Line TRUE FALSE TRUE UK .NTF UK .NTF FALSE FALSE TRUE VDV VDV-451/VDV-452/INTREST Data Format TRUE FALSE TRUE VFK Czech Cadastral Exchange Data Format FALSE FALSE TRUE Walk Walk FALSE FALSE TRUE WAsP WAsP .map format TRUE FALSE TRUE WFS OGC WFS (Web Feature Service) FALSE FALSE TRUE XLS MS Excel format FALSE FALSE TRUE XLSX MS Office Open XML spreadsheet TRUE FALSE TRUE XPlane X-Plane/Flightgear aeronautical data FALSE FALSE TRUE Or rgdal::gdalDrivers() for raster drivers: name long_name create copy isRaster AAIGrid Arc/Info ASCII Grid FALSE TRUE TRUE ACE2 ACE2 FALSE FALSE TRUE ADRG ARC Digitized Raster Graphics TRUE FALSE TRUE AIG Arc/Info Binary Grid FALSE FALSE TRUE AirSAR AirSAR Polarimetric Image FALSE FALSE TRUE ARG Azavea Raster Grid format FALSE TRUE TRUE BAG Bathymetry Attributed Grid FALSE FALSE TRUE BIGGIF Graphics Interchange Format (.gif) FALSE FALSE TRUE BLX Magellan topo (.blx) FALSE TRUE TRUE BMP MS Windows Device Independent Bitmap TRUE FALSE TRUE BSB Maptech BSB Nautical Charts FALSE FALSE TRUE BT VTP .bt (Binary Terrain) 1.3 Format TRUE FALSE TRUE CAD AutoCAD Driver FALSE FALSE TRUE CALS CALS (Type 1) FALSE TRUE TRUE CEOS CEOS Image FALSE FALSE TRUE COASP DRDC COASP SAR Processor Raster FALSE FALSE TRUE COSAR COSAR Annotated Binary Matrix (TerraSAR-X) FALSE FALSE TRUE CPG Convair PolGASP FALSE FALSE TRUE CTable2 CTable2 Datum Grid Shift TRUE FALSE TRUE CTG USGS LULC Composite Theme Grid FALSE FALSE TRUE DERIVED Derived datasets using VRT pixel functions FALSE FALSE TRUE DIMAP SPOT DIMAP FALSE FALSE TRUE DIPEx DIPEx FALSE FALSE TRUE DODS DAP 3.x servers FALSE FALSE TRUE DOQ1 USGS DOQ (Old Style) FALSE FALSE TRUE DOQ2 USGS DOQ (New Style) FALSE FALSE TRUE DTED DTED Elevation Raster FALSE TRUE TRUE E00GRID Arc/Info Export E00 GRID FALSE FALSE TRUE ECRGTOC ECRG TOC format FALSE FALSE TRUE EHdr ESRI .hdr Labelled TRUE TRUE TRUE EIR Erdas Imagine Raw FALSE FALSE TRUE ELAS ELAS TRUE FALSE TRUE ENVI ENVI .hdr Labelled TRUE FALSE TRUE EPSILON Epsilon wavelets FALSE TRUE TRUE ERS ERMapper .ers Labelled TRUE FALSE TRUE ESAT Envisat Image Format FALSE FALSE TRUE FAST EOSAT FAST Format FALSE FALSE TRUE FIT FIT Image FALSE TRUE TRUE FujiBAS Fuji BAS Scanner Image FALSE FALSE TRUE GenBin Generic Binary (.hdr Labelled) FALSE FALSE TRUE GFF Ground-based SAR Applications Testbed File Format (.gff) FALSE FALSE TRUE GIF Graphics Interchange Format (.gif) FALSE TRUE TRUE GMT GMT NetCDF Grid Format FALSE TRUE TRUE GPKG GeoPackage TRUE TRUE TRUE GRASSASCIIGrid GRASS ASCII Grid FALSE FALSE TRUE GRIB GRIdded Binary (.grb) FALSE FALSE TRUE GS7BG Golden Software 7 Binary Grid (.grd) TRUE TRUE TRUE GSAG Golden Software ASCII Grid (.grd) FALSE TRUE TRUE GSBG Golden Software Binary Grid (.grd) TRUE TRUE TRUE GSC GSC Geogrid FALSE FALSE TRUE GTiff GeoTIFF TRUE TRUE TRUE GTX NOAA Vertical Datum .GTX TRUE FALSE TRUE GXF GeoSoft Grid Exchange Format FALSE FALSE TRUE HDF4 Hierarchical Data Format Release 4 FALSE FALSE TRUE HDF4Image HDF4 Dataset TRUE FALSE TRUE HDF5 Hierarchical Data Format Release 5 FALSE FALSE TRUE HDF5Image HDF5 Dataset FALSE FALSE TRUE HF2 HF2/HFZ heightfield raster FALSE TRUE TRUE HFA Erdas Imagine Images (.img) TRUE TRUE TRUE HTTP HTTP Fetching Wrapper FALSE FALSE TRUE IDA Image Data and Analysis TRUE FALSE TRUE ILWIS ILWIS Raster Map TRUE TRUE TRUE INGR Intergraph Raster TRUE TRUE TRUE IRIS IRIS data (.PPI, .CAPPi etc) FALSE FALSE TRUE ISCE ISCE raster TRUE FALSE TRUE ISIS2 USGS Astrogeology ISIS cube (Version 2) TRUE FALSE TRUE ISIS3 USGS Astrogeology ISIS cube (Version 3) TRUE TRUE TRUE JAXAPALSAR JAXA PALSAR Product Reader (Level 1.1/1.5) FALSE FALSE TRUE JDEM Japanese DEM (.mem) FALSE FALSE TRUE JP2OpenJPEG JPEG-2000 driver based on OpenJPEG library FALSE TRUE TRUE JPEG JPEG JFIF FALSE TRUE TRUE KMLSUPEROVERLAY Kml Super Overlay FALSE TRUE TRUE KRO KOLOR Raw TRUE FALSE TRUE L1B NOAA Polar Orbiter Level 1b Data Set FALSE FALSE TRUE LAN Erdas .LAN/.GIS TRUE FALSE TRUE LCP FARSITE v.4 Landscape File (.lcp) FALSE TRUE TRUE Leveller Leveller heightfield TRUE FALSE TRUE LOSLAS NADCON .los/.las Datum Grid Shift FALSE FALSE TRUE MAP OziExplorer .MAP FALSE FALSE TRUE MBTiles MBTiles TRUE TRUE TRUE MEM In Memory Raster TRUE FALSE TRUE MFF Vexcel MFF Raster TRUE TRUE TRUE MFF2 Vexcel MFF2 (HKV) Raster TRUE TRUE TRUE MRF Meta Raster Format TRUE TRUE TRUE MSGN EUMETSAT Archive native (.nat) FALSE FALSE TRUE NDF NLAPS Data Format FALSE FALSE TRUE netCDF Network Common Data Format TRUE TRUE TRUE NGSGEOID NOAA NGS Geoid Height Grids FALSE FALSE TRUE NITF National Imagery Transmission Format TRUE TRUE TRUE NTv2 NTv2 Datum Grid Shift TRUE FALSE TRUE NWT_GRC Northwood Classified Grid Format .grc/.tab FALSE FALSE TRUE NWT_GRD Northwood Numeric Grid Format .grd/.tab TRUE TRUE TRUE OGDI OGDI Bridge FALSE FALSE TRUE OZI OziExplorer Image File FALSE FALSE TRUE PAux PCI .aux Labelled TRUE FALSE TRUE PCIDSK PCIDSK Database File TRUE FALSE TRUE PCRaster PCRaster Raster File TRUE TRUE TRUE PDF Geospatial PDF TRUE TRUE TRUE PDS NASA Planetary Data System FALSE FALSE TRUE PLMOSAIC Planet Labs Mosaics API FALSE FALSE TRUE PLSCENES Planet Labs Scenes API FALSE FALSE TRUE PNG Portable Network Graphics FALSE TRUE TRUE PNM Portable Pixmap Format (netpbm) TRUE FALSE TRUE PostGISRaster PostGIS Raster driver FALSE TRUE TRUE PRF Racurs PHOTOMOD PRF FALSE FALSE TRUE R R Object Data Store FALSE TRUE TRUE Rasterlite Rasterlite FALSE TRUE TRUE RIK Swedish Grid RIK (.rik) FALSE FALSE TRUE RMF Raster Matrix Format TRUE FALSE TRUE ROI_PAC ROI_PAC raster TRUE FALSE TRUE RPFTOC Raster Product Format TOC format FALSE FALSE TRUE RRASTER R Raster FALSE FALSE TRUE RS2 RadarSat 2 XML Product FALSE FALSE TRUE RST Idrisi Raster A.1 TRUE TRUE TRUE SAFE Sentinel-1 SAR SAFE Product FALSE FALSE TRUE SAGA SAGA GIS Binary Grid (.sdat) TRUE TRUE TRUE SAR_CEOS CEOS SAR Image FALSE FALSE TRUE SDTS SDTS Raster FALSE FALSE TRUE SENTINEL2 Sentinel 2 FALSE FALSE TRUE SGI SGI Image File Format 1.0 TRUE FALSE TRUE SNODAS Snow Data Assimilation System FALSE FALSE TRUE SRP Standard Raster Product (ASRP/USRP) FALSE FALSE TRUE SRTMHGT SRTMHGT File Format FALSE TRUE TRUE Terragen Terragen heightfield TRUE FALSE TRUE TIL EarthWatch .TIL FALSE FALSE TRUE TSX TerraSAR-X Product FALSE FALSE TRUE USGSDEM USGS Optional ASCII DEM (and CDED) FALSE TRUE TRUE VICAR MIPL VICAR file FALSE FALSE TRUE VRT Virtual Raster TRUE TRUE TRUE WCS OGC Web Coverage Service FALSE FALSE TRUE WEBP WEBP FALSE TRUE TRUE WMS OGC Web Map Service FALSE TRUE TRUE WMTS OGC Web Mab Tile Service FALSE TRUE TRUE XPM X11 PixMap Format FALSE TRUE TRUE XYZ ASCII Gridded XYZ FALSE TRUE TRUE ZMap ZMap Plus Grid FALSE TRUE TRUE Lots!!! But note that there are others that are not supported in R. Perhaps the most common unsupported ones you’ll encounter are the ESRI geodatabases (.gdb and .mdb), which are designed for ArcGIS and are super efficient (in ArcGIS), but ESRI haven’t released the drivers, so they don’t work (or at least not properly) for most other GIS software… Note that there has been a big push to develop a standardized set of open source, efficient and interoperable file formats. Some examples to watch: GeoPackage - SQLite database containers for storing vector, raster and attribute data in a compact and transferable format. GeoJSON - a geographic version of JSON (JavaScript Object Notation) for vector data, very commonly used for web apps etc. Cloud-optimized GeoTIFF - as the name suggests; a GeoTIFF-based format for optimally hosting and allowing querying and downloading of raster data on the cloud… Simple Features - an open, efficient and interoperable standard for vector data. "],["some-important-concepts-and-pitfalls.html", "5 Some important concepts and pitfalls 5.1 Scale 5.2 Coordinate Reference Systems (CRS)", " 5 Some important concepts and pitfalls 5.1 Scale All maps have a scale. Scale is the ratio between the size of the representation of an object and its size in reality. E.g. objects on a 1:50,000 scale map are drawn at 1/50,000 their size, so 1cm on the map represents a distance of 500m in reality (i.e. \\(1*50,000 = 50,000cm = 500m\\)). Figure 5.1: The Cape Peninsula (3418AB &amp; AD) from South Africa’s 1:50,000 topographic map series. The printed scale for these maps is 1:50,000, but what is it on your screen? GIS is usually scaleless (or at least flexible in scale); we can “zoom in” as much as we want to, and perform operations at just about any scale we want to, but should we? There are lots of issues we need to consider! Representation (i.e. mapping)… There are 2 issues here: Firstly, a 1mm thick line on a 1:50,000 scale map would be 50m wide in reality. Conversely, a 5m wide road would be 1/10mm on the map. Would the map be readable? Sometimes we break the rules of scale to make maps readable. Bear this in mind! Secondly, scale and our desired representation affect how we capture data. For example, a road is typically best represented as a line at 1:5,000 scale or smaller (note that scale is a ratio, so “small scale” = large extent or area!). At 1:1,000 scale a 5m wide road would be 5mm across on the map, so one might capture it as a polygon to represent its area. You should always consider the purpose for which (and scale at which) the data were captured before using them for a new application! This affects both the appropriateness of the data type and the accuracy and precision of the data… Figure 5.2: Zoomed in on Chapman’s peak on the the Cape Peninsula 1:50,000 topographic map (3418AB &amp; AD). At this scale the road (in red) is probably better mapped as an area than a line? Accuracy of location versus scale of data capture. We should always check the scale at which the data were captured to make sure it is accurate enough for the scale of the analysis we are doing. For example, the various vegetation units in the National Vegetation Map of South Africa were mapped at a range of scales, some as small as 1:250,000. At this scale 1mm = 250m, so a minor digitization error is a huge difference on the ground! If you need your analysis to be accurate to &lt;10m then you’d probably need data mapped at a scale larger than 1:10,000. Precision - Can mean two things: The unit or number of decimal places to which the attribute has been measured (and can be stored) The spread of repeat measurements (typically in field data collection). A big spread means the measurements weren’t very precise… A quick aside on the difference between accuracy and precision! Figure 5.3: The difference between accuracy and precision, where the true value is the origin (0,0). A last word on Scale… For vector data, we typically refer to scale when describing a data set. For raster data, we typically refer to pixel resolution (or sample interval). For example, a 30m digital elevation model is made up of pixels 30m across. For remotely sensed imagery (i.e. from drone, plane or satellite), one often uses the term “ground sample distance.” BEWARE!!! If you convert between raster and vector data formats (e.g. by “rasterizing” a vector layer, or “binning” a raster into polygons), it will affect all three of precision, accuracy and representation, so you need to give careful thought to whether what you are doing is appropriate for the analysis you are doing! 5.2 Coordinate Reference Systems (CRS) Coordinate Reference Systems (CRS) provide a framework for defining real-world locations. There are many different CRSs, with different properties. They can be a minefield, and I don’t have the time to cover them in any detail. I provide some of the basics here, and list some of the golden rules (mostly from the GIS Support Unit) below. 5.2.1 Geographic (or “unprojected”) Coordinate Systems The most common coordinate system is latitude/longitude, also known as geographic, lat/long or sometimes WGS84. There are many ways to record geographic coordinates: Degrees, Minutes &amp; Seconds: S33°26’46”,E18°10’23’’ Decimal Degrees: -33.4461111,18.17305556 Most GIS prefer decimal degrees… The problem with doing analyses using geographic CRS is that lat/long coordinates are actually angular measurements on a 3D sphere (Geodesic) and degrees differ in their actual ground distance depending on where you are on the planet. They also differ in the N-S vs W-E plane! Figure 5.4: Map highlighting that a degree is larger at the equator than at the poles. Image source: https://annakrystalli.me/intro-r-gis/gis.html This means that Euclidean measurement calculations are not appropriate for calculating areas and distances. 5.2.2 Projected Coordinate Systems To perform linear measurements from a 3D shape using Euclidean methods, you need to squash that shape into a 2D plane. This squashing is called a projection… Figure 5.5: How many different ways could you flatten a naartjie peel? There are 4 properties that get distorted, you can pick which one gets preserved the best by a projection type: Shape - you want a Conformal projection Area - Equal-Area Distance - Equidistant Direction - Azimuthal (see here for a nice description and illustrations) Some “general purpose” projections, like Transverse Mercator (TM), try to compromise and minimize distortion in all properties, but can’t preserve any perfectly. Their distortions also tend to get worse the larger the spatial extent being analyzed. Projections get tuned to best fit an area through the use of projection parameters. For example, Transverse Mercator, which is used by the 1:50,000 map series and by Municipalities like Cape Town, uses a narrow projection window of 2 degree-wide bands. As a result, our map series projection parameters are set by moving the central meridian (or tangent) line of longitude every odd degree across the country. Cape Town is close to 19°E, so our version is colloquially called ‘Lo19.’ For Durban you’d use ‘Lo31.’ Universal Transverse Mercator (UTM) is similar, but uses 6 degree-wide bands so that it can be applied across larger extents. 5.2.3 Projection codes The type of CRS is usually (but not always) stored in the metadata of your file (or dataset, if it is comprised of multiple files like an ESRI shapefile). There are various formats for this, such as EPSG, PROJ4 or WKT (be warned, there are many more…). In R, to apply a CRS or reproject your data you typically need to know the EPSG or PROJ4 code. Fortunately, there is a huge online library of these at https://spatialreference.org/. I also provide some suggested projections, based on the properties you’d like to preserve, and their codes here. Note that for UTM and TM you may need to adjust the PROJ4 strings for your area - read the comments. Why do projections matter? Figure 5.6: Africa, visualized with different coordinate reference systems. All four maps are different, even if the differences may be subtle! 5.2.4 “On the fly” vs manual projection Note that some GIS tools can perform “on the fly” (re)projection of data. For example, by default ArcGIS sets the CRS for a project from the first dataset imported. When you want to visualize the data, it will reproject all other datasets to the set CRS so that it can visualize it properly. Similarly, ArcGIS and other software can project data in a geographic CRS to a projected CRS on the fly when asked to perform Euclidean measurement calculations. On the fly projection can clearly be very useful, but it can also be misleading if you don’t know what its doing. My take is that you should always check the default settings for the software you’re using, and check the set CRS(s) and individual dataset CRS(s) to make sure you are working in a suitable CRS for the operations you want to perform… 5.2.5 The golden rules… If things don’t line up, its probably a CRS issue. You need to know what CRS your dataset is in. This is essential, because you need to define your projections to be able to compare datasets. If they are not the same, you will need to reproject one to align with the other*. If your datasets are not in the same CRS, most GIS software will give you warning or error messages, but not always! Note that not all file formats store the CRS “metadata,” so check and store it yourself if needed! You need to make sure you use a CRS that best preserves the properties you are interested in (area, distance, direction, shape). More on this below in section 5.2.2. If your areas and distances are stupidly small (0.001 etc) your data are probably in Geographic (i.e. degrees and not a unit of distance like metres). Always interrogate and “common-sense-check” your results!!! *Defining Projection is not the same as reprojecting! Think in terms of languages, “I have text in Japanese and want it in English.” Defining is saying what it IS (“This text is in Japanese” - defining Japanese as English gives you garbage). Reprojecting is what you want it to be (i.e. translate Japanese to English). Two other issues to look out for: The official South African CRS is waiting to get you. If you see Gauss Conform run screaming, its a left handed CRS based on Southings and Westings (i.e. completely inverted…). Simple, yes? Datums… These are essentially models of the shape of the surface of the planet. Most South African datasets (since 1999 at least) use the Hartebeesthoek 94 datum, which is our local “bespoke” solution. It’s pretty much the same as the WGS84 datum (a good global datum), and the difference is negligible for most ecological analyses. Our former local “bespoke” datum (the Cape or Clarke1880 datum), which was often used for data before 1999, is out to get you. These datasets will never line up perfectly with modern data sets when reprojected in a normal GIS and will usually be a couple of tens of metres off… Some other important pitfalls to avoid are best covered in this chapter in Manny Gimond’s Intro to GIS and Spatial Analysis. "],["r-as-a-gis.html", "6 R as a GIS 6.1 Overview 6.2 Some key R packages", " 6 R as a GIS 6.1 Overview Points, lines, polygons and rasters - R can handle them all and more! R is a free software environment for statistical computing and graphics, but its abilities have been extended into many realms through the ~18,000 (!) contributed extension packages (also called libraries). The list of packages can be bewildering, but fortunately some great folks have taken the time to sift through and make some sense of them for different focal topics and created Task Views. For GIS there are two Task Views of interest: Spatial - maintained by Roger Bivand, and SpatioTemporal - maintained by Edzer Pebesma They overlap somewhat, but the latter specifically focuses on data where both location and time of observation are registered, and relevant for the analysis of the data. Each has an overview page listing packages and highlighting their respective strengths, weaknesses etc., e.g. Figure 6.1: Screenshot of the “Spatial” Task View at https://cran.r-project.org/ The Spatial Task View focuses on “Analysis of Spatial Data,” with sections on: Classes for spatial data and metadata Reading and writing spatial data Handling spatial data Analyzing spatial data Task Views also allow easy download and installation of all packages in a Task View using library(ctv)! - see code below. But beware! It can take a while to download and install if it is a big Task View and the Spatial one is BIG!!! You don’t need the whole Task View for my tutorials, so don’t bother downloading it if you’re just working through these. Figure 6.2: Screenshot of the Task View landing page at https://cran.r-project.org/ Since you can’t copy the code from the image, here it is: install.packages(\"ctv\") ctv::install.views(\"Spatial\") 6.2 Some key R packages We don’t have time to go through all packages or provide a full history, but here are some notes in brief. 6.2.1 For vector data (although some of these packages can handle rasters too) The two leading packages were sp and rgdal. While these are still very active and useful, they are being superseded by a newer package sf, which is a modern implementation and standardization of parts of sp. sf stands for “Simple Features for R,” in compliance with the OGC Simple Feature standard. It is highly efficient, and comes with the advantage that it uses Tidyverse principles and coding styles, e.g. allowing use of the pipe operator (%&gt;%) and the direct application of library(dplyr) data manipulation and library(ggplot2) visualization functions. I will use sf for the most part in the demonstration material. Unfortunately, not all operations are available in sf yet and I may still have to use sp at times, especially when performing operations using both vector and raster data. If you’d like o learn more about using sp, check out this tutorial I put together a few years ago. Here’s a quick list of the functions available in sf: library(sf) methods(class = &#39;sf&#39;) ## [1] [ ## [2] [[&lt;- ## [3] $&lt;- ## [4] aggregate ## [5] anti_join ## [6] arrange ## [7] as.data.frame ## [8] cbind ## [9] coerce ## [10] dbDataType ## [11] dbWriteTable ## [12] distinct ## [13] dplyr_reconstruct ## [14] extent ## [15] extract ## [16] filter ## [17] full_join ## [18] gather ## [19] group_by ## [20] group_split ## [21] identify ## [22] initialize ## [23] inner_join ## [24] left_join ## [25] mask ## [26] merge ## [27] mutate ## [28] nest ## [29] plot ## [30] print ## [31] raster ## [32] rasterize ## [33] rbind ## [34] rename ## [35] right_join ## [36] rowwise ## [37] sample_frac ## [38] sample_n ## [39] select ## [40] semi_join ## [41] separate_rows ## [42] separate ## [43] show ## [44] slice ## [45] slotsFromS3 ## [46] spread ## [47] st_agr ## [48] st_agr&lt;- ## [49] st_area ## [50] st_as_s2 ## [51] st_as_sf ## [52] st_bbox ## [53] st_boundary ## [54] st_buffer ## [55] st_cast ## [56] st_centroid ## [57] st_collection_extract ## [58] st_convex_hull ## [59] st_coordinates ## [60] st_crop ## [61] st_crs ## [62] st_crs&lt;- ## [63] st_difference ## [64] st_filter ## [65] st_geometry ## [66] st_geometry&lt;- ## [67] st_inscribed_circle ## [68] st_interpolate_aw ## [69] st_intersection ## [70] st_intersects ## [71] st_is_valid ## [72] st_is ## [73] st_join ## [74] st_line_merge ## [75] st_m_range ## [76] st_make_valid ## [77] st_nearest_points ## [78] st_node ## [79] st_normalize ## [80] st_point_on_surface ## [81] st_polygonize ## [82] st_precision ## [83] st_reverse ## [84] st_sample ## [85] st_segmentize ## [86] st_set_precision ## [87] st_shift_longitude ## [88] st_simplify ## [89] st_snap ## [90] st_sym_difference ## [91] st_transform ## [92] st_triangulate ## [93] st_union ## [94] st_voronoi ## [95] st_wrap_dateline ## [96] st_write ## [97] st_z_range ## [98] st_zm ## [99] summarise ## [100] transform ## [101] transmute ## [102] ungroup ## [103] unite ## [104] unnest ## see &#39;?methods&#39; for accessing help and source code This doesn’t tell you how to use them though. To get help with a function in R just type “?” followed by the function name, e.g. ?st_read, and it’ll take you to the help page. Of course, you don’t want to have to read every help page to find the function you want! Fortunately, here’s a “cheat sheet” that allows you to find the function you want relatively quickly (once you’re familiar with the syntax etc): Figure 6.3: An R cheat sheet for library(sf) by Ryan Garnett (page 1). Figure 6.4: An R cheat sheet for library(sf) by Ryan Garnett (page 2). 6.2.2 For raster data By far the best package has been raster, maintained by Robert Hijmans (of WorldClim fame), and can do just about anything with rasters and interfaces with sp very nicely. raster is currently being superseded by a new package called terra, also being developed by Hijmans. “terra is very similar to the raster package; but terra is simpler, better, and faster” - Roger Bivand I’ve never used terra before developing this module, and it is still largely in development, so for most of the demonstrations we will use raster. Unfortunately, there’s no cheat sheet for raster or terra, but Google really helps!!! "],["rdemo.html", "7 Vector GIS operations in R 7.1 Case study and demo datasets 7.2 Reading and writing 7.3 Basic plotting 7.4 Cropping 7.5 Select and subset by attribute 7.6 Combine classes and dissolve by attribute 7.7 Calling iNaturalist locality (point) data from R 7.8 Converting a dataframe into a spatial object 7.9 Adding basemaps to plots 7.10 Interactive maps with leaflet 7.11 Reprojecting 7.12 Intersecting points and polygons 7.13 Colour or label points 7.14 Buffering 7.15 Within distance and intersect", " 7 Vector GIS operations in R 7.1 Case study and demo datasets Ok, for demonstrating some of the many GIS operations R can perform we will be using data from one of my favourite study areas, the Cape Peninsula. The datasets we will use, some of their properties and where to source them are tabled below: Name Data.model Geometry.type File.format Data.source URL Localities Vector Point iNaturalist https://www.inaturalist.org/ Watercourses Vector Line ESRI shapefile City of Cape Town https://odp-cctegis.opendata.arcgis.com/datasets/cctegis::open-watercourses/about Vegetation Types (historical) Vector Polygon ESRI shapefile City of Cape Town https://odp-cctegis.opendata.arcgis.com/datasets/cctegis::indigenous-vegetation-historic-extent/about Vegetation Types (remnants) Vector Polygon ESRI shapefile City of Cape Town https://odp-cctegis.opendata.arcgis.com/datasets/indigenous-vegetation-current-extent Elevation Raster Raster GeoTIFF City of Cape Town https://odp-cctegis.opendata.arcgis.com/datasets/digital-elevation-model-10m-grid-general-binary-ascii If you’d like to follow along and run the analyses that follow, please follow the links and download the datasets. If you don’t see the links, you need to reduce the font size by clicking the “A” in the taskbar. The elevation dataset is ~13MB as a .zip file, but will expand to ~130MB . I’ll also put a copy of all datasets on the Vula site for the course, which I understand is zero-data rated. There’s no need to download the iNaturalist data as we’ll download it directly from R. For installing R and the required packages see section 1.2. 7.2 Reading and writing sf has a one-size-fits-all approach in that most functions can be applied to most different data types (point, line, polygon, etc) or, in the case of reading and writing, file formats. To read data the function you want is st_read(). You’ll note that most of the sf functions begin with “st_” - this stands for “spatial and temporal” and is the same in some other GIS like PostGIS. Let’s try to read in some data with st_read(): NOTE: if you’re trying any of the read/write code at home, you’ll need to set the file path to where you put the data and want the outputs on your local machine. You can also use ?setwd to simplify this. If you are on Windows, make sure to change the backslashes “\" to either double backslashes or forward slashes”/\". library(sf) veg &lt;- st_read(&quot;data/cape_peninsula/veg/Vegetation_Indigenous.shp&quot;) ## Reading layer `Vegetation_Indigenous&#39; from data source `/home/jasper/GIT/spatial-r/data/cape_peninsula/veg/Vegetation_Indigenous.shp&#39; using driver `ESRI Shapefile&#39; ## Simple feature collection with 1325 features and 5 fields ## Geometry type: POLYGON ## Dimension: XY ## Bounding box: xmin: -63972.95 ymin: -3803535 xmax: 430.8125 ymax: -3705149 ## proj4string: +proj=tmerc +lat_0=0 +lon_0=19 +k=1 +x_0=0 +y_0=0 +ellps=WGS84 +units=m +no_defs This has successfully read in the data and given us a summary of some of its properties. Note the projection (proj4string). This is Transverse Mercator Lo19 (i.e. centred on the 19 degree line of longitude), which has a unit in metres (see the bounding box coordinates). It’s a good projection for most calculations at this scale (and on this line of longitude*). *If you’re using Transverse Mercator, always make sure it is set for your closest “odd” line of longitude (i.e. Lo19, Lo21, Lo23)! Let’s have a closer look at the data: class(veg) ## [1] &quot;sf&quot; &quot;data.frame&quot; It is an object of two different “classes,” a data.frame, which is an R object class you should be familiar with, and class sf, which is the native class for the sf library. The nice thing about being both classes is it means you can apply the functions built for either class, e.g. head(veg) ## Simple feature collection with 6 features and 5 fields ## Geometry type: POLYGON ## Dimension: XY ## Bounding box: xmin: -51324.95 ymin: -3732075 xmax: -35653.98 ymax: -3718136 ## proj4string: +proj=tmerc +lat_0=0 +lon_0=19 +k=1 +x_0=0 +y_0=0 +ellps=WGS84 +units=m +no_defs ## AREA_HCTR PRMT_MTR ## 1 1807.5183616 24763.8073 ## 2 2.1437754 609.5892 ## 3 0.2134855 185.5566 ## 4 2.8602421 652.1671 ## 5 0.5468058 336.8006 ## 6 0.4172046 259.7772 ## National_ ## 1 Atlantis Sand Fynbos ## 2 Atlantis Sand Fynbos ## 3 Atlantis Sand Fynbos ## 4 Atlantis Sand Fynbos ## 5 Atlantis Sand Fynbos ## 6 Atlantis Sand Fynbos ## Subtype ## 1 on marine-derived acid sands ## 2 on marine-derived acid sands ## 3 on marine-derived acid sands ## 4 on marine-derived acid sands ## 5 on marine-derived acid sands ## 6 on marine-derived acid sands ## Community ## 1 Need to Find Out ## 2 Need to Find Out ## 3 Need to Find Out ## 4 Need to Find Out ## 5 Need to Find Out ## 6 Need to Find Out ## geometry ## 1 POLYGON ((-48203.88 -372294... ## 2 POLYGON ((-36676.72 -371974... ## 3 POLYGON ((-35891.46 -371837... ## 4 POLYGON ((-35750.07 -371847... ## 5 POLYGON ((-35823.89 -371817... ## 6 POLYGON ((-35929.18 -371824... This is a commonly used function for looking at the first few rows of a dataframe. Note there are 5 attribute columns and a 6th geometry column. All sf objects have a geometry column. This is where it stores the geometry - i.e. the point, line, polygon etc - associated with each row of attribute data. To write data with sf you use st_write(), like so: st_write(veg, &quot;data/cape_peninsula/veg/Vegetation_Indigenous_duplicate.shp&quot;) ## Writing layer `Vegetation_Indigenous_duplicate&#39; to data source `data/cape_peninsula/veg/Vegetation_Indigenous_duplicate.shp&#39; using driver `ESRI Shapefile&#39; ## Writing 1325 features with 5 fields and geometry type Polygon. file.exists(&quot;data/cape_peninsula/veg/Vegetation_Indigenous_duplicate.shp&quot;) # Just to confirm for you that the file exists ## [1] TRUE Note that the function recognised that I wanted to write out an ESRI shapefile from the .shp file extension I provided. You can set the file type using the driver = setting in st_write(). Try st_drivers() for the list of file types supported. 7.3 Basic plotting As with other data types in R (and perhaps even more so with spatial data), you can really go to town with plotting. I’m only going to show you enough to be able to interrogate your data. Making it look pretty is a week-long course or more in its own right. Check out the “Making maps with R” chapter in Lovelace et al’s online book Geocomputation with R for a good start. The easiest way to plot datasets in R is often a bad thing to do when working with spatial datasets! plot(veg) Fortunately, in this case the dataset isn’t too big, but often you’ll either be overwhelmed with plots or your computer will crash… Why 5 plots and not one? This is because sf wants to plot the properties of each attribute in the attribute table. Fortunately, there were only 5, but there could have been hundreds! You can select the one you want with indexing like so: plot(veg[3]) These are the National Vegetation Types for the City of Cape Town municipality. You’ll note that we’re using the base R graphics functions. I mentioned before that sf integrates well with the Tidyverse, so this could also be plotted like so: library(tidyverse) #calls ggplot2 and other Tidyverse packages together ggplot() + geom_sf(data=veg, aes(fill = `National_`)) That’s better for the legend, but now we’ve squashed the map. Let’s narrow in on the Cape Peninsula for convenience. 7.4 Cropping Here we’ll apply the function st_crop(). To use the function you need an object to crop, and an extent or bounding box to crop to. sf is clever, and you can set the extent by giving it another object who’s extent you’d like to match (check the bounding box given when we read in the data earlier). We don’t have a second object in this case, so we have to provide a “numeric vector with named elements xmin, ymin, xmax and ymax,” like so: #Make a vector of coordinates in metres according to TM Lo19 ext &lt;- c(-66642.18, -3809853.29, -44412.18, -3750723.29) ext ## [1] -66642.18 -3809853.29 -44412.18 ## [4] -3750723.29 #Give the vector names names(ext) &lt;- c(&quot;xmin&quot;, &quot;ymin&quot;, &quot;xmax&quot;, &quot;ymax&quot;) ext ## xmin ymin xmax ## -66642.18 -3809853.29 -44412.18 ## ymax ## -3750723.29 Now we can feed that into st_crop veg &lt;- st_crop(veg, ext) #Note that I&#39;m overwriting the old data object ## Warning: attribute variables are assumed to be ## spatially constant throughout all geometries ggplot() + geom_sf(data=veg, aes(fill = `National_`)) Better? But what about the silly splits like Peninsula Granite Fynbos - North/South and Cape Flats Dune Strandveld - West Coast/False Bay. Which ones do I mean? 7.5 Select and subset by attribute Let’s select them from the attribute table and plot them. #Make a vector of the veg types we want split_veg &lt;- c(&quot;Peninsula Granite Fynbos - North&quot;, &quot;Peninsula Granite Fynbos - South&quot;, &quot;Cape Flats Dune Strandveld - West Coast&quot;, &quot;Cape Flats Dune Strandveld - False Bay&quot;) #Use base R indexing to select attributes vegsub &lt;- veg[which(veg$National_ %in% split_veg),] #Plot ggplot() + geom_sf(data=vegsub, aes(fill = `National_`)) Or tidyverse… #Using tidyverse piping to filter and plot veg %&gt;% filter(National_ %in% split_veg) %&gt;% ggplot() + geom_sf(aes(fill = `National_`)) #The advantage being that you don&#39;t have to make the intermediate &quot;vegsub&quot; object Ok. What if we decided we don’t want them split? 7.6 Combine classes and dissolve by attribute We can just rename them in appropriate column in the attribute table… vegsub$National_ &lt;- str_replace_all(vegsub$National_, c(&quot;Peninsula Granite Fynbos - North&quot; = &quot;Peninsula Granite Fynbos&quot;, &quot;Peninsula Granite Fynbos - South&quot; = &quot;Peninsula Granite Fynbos&quot;, &quot;Cape Flats Dune Strandveld - West Coast&quot; = &quot;Cape Flats Dune Strandveld&quot;, &quot;Cape Flats Dune Strandveld - False Bay&quot; = &quot;Cape Flats Dune Strandveld&quot;)) ggplot() + geom_sf(data=vegsub, aes(fill = `National_`)) Nice, but from the polygon boundaries we see that there are a number of adjacent polygons (i.e. they have shared boundaries) that are of the same veg type. We can “dissolve” and plot these boundaries like so: vegsub %&gt;% group_by(National_) %&gt;% summarize() %&gt;% ggplot() + geom_sf(aes(fill = National_)) Ok… I think we’ve flogged that horse as far as it’ll go for now. Let’s bring in another dataset. How about points? 7.7 Calling iNaturalist locality (point) data from R A very cool feature of iNaturalist is that the team at rOpenSci have built a great R package for interfacing with it directly, called rinat! Let’s get all the records we can for the King Protea (Protea cynaroides). library(rinat) #Call the data directly from iNat pc &lt;- get_inat_obs(taxon_name = &quot;Protea cynaroides&quot;, bounds = c(-35, 18, -33.5, 18.5), maxresults = 1000) #Filter returned observations by a range of attribute criteria pc &lt;- pc %&gt;% filter(positional_accuracy&lt;46 &amp; latitude&lt;0 &amp; !is.na(latitude) &amp; captive_cultivated == &quot;false&quot; &amp; quality_grade == &quot;research&quot;) class(pc) ## [1] &quot;data.frame&quot; Ok, so this is a dataframe with lat/long data, but it isn’t registered as an object with spatial attributes (i.e. geometries). 7.8 Converting a dataframe into a spatial object To make it an object of class(sf) we use the function st_as_sf(). #Make the dataframe a spatial object of class = &quot;sf&quot; pc &lt;- st_as_sf(pc, coords = c(&quot;longitude&quot;, &quot;latitude&quot;), crs = 4326) #Note that I had to define the CRS (as Geographic WGS84)!!! #What class is it? class(pc) ## [1] &quot;sf&quot; &quot;data.frame&quot; #Note the new &quot;geometry&quot; column names(pc) ## [1] &quot;scientific_name&quot; ## [2] &quot;datetime&quot; ## [3] &quot;description&quot; ## [4] &quot;place_guess&quot; ## [5] &quot;tag_list&quot; ## [6] &quot;common_name&quot; ## [7] &quot;url&quot; ## [8] &quot;image_url&quot; ## [9] &quot;user_login&quot; ## [10] &quot;id&quot; ## [11] &quot;species_guess&quot; ## [12] &quot;iconic_taxon_name&quot; ## [13] &quot;taxon_id&quot; ## [14] &quot;num_identification_agreements&quot; ## [15] &quot;num_identification_disagreements&quot; ## [16] &quot;observed_on_string&quot; ## [17] &quot;observed_on&quot; ## [18] &quot;time_observed_at&quot; ## [19] &quot;time_zone&quot; ## [20] &quot;positional_accuracy&quot; ## [21] &quot;public_positional_accuracy&quot; ## [22] &quot;geoprivacy&quot; ## [23] &quot;taxon_geoprivacy&quot; ## [24] &quot;coordinates_obscured&quot; ## [25] &quot;positioning_method&quot; ## [26] &quot;positioning_device&quot; ## [27] &quot;user_id&quot; ## [28] &quot;created_at&quot; ## [29] &quot;updated_at&quot; ## [30] &quot;quality_grade&quot; ## [31] &quot;license&quot; ## [32] &quot;sound_url&quot; ## [33] &quot;oauth_application_id&quot; ## [34] &quot;captive_cultivated&quot; ## [35] &quot;geometry&quot; #Plot ggplot() + geom_sf(data=pc) Great! We got lots of points, but without a base layer its very difficult to tell where exactly these are? 7.9 Adding basemaps to plots There are lots of ways to make the basemap from data objects etc that we can plot our points over, but an easy way is to pull in tiles from Open Street Maps and plot our points on those. library(rosm) library(ggspatial) ggplot() + annotation_map_tile(type = &quot;osm&quot;, progress = &quot;none&quot;) + geom_sf(data=pc) Note that there are quite a few base layer/tile options that can be set with type = \"\". Try rosm::osm.types() to see them all. This is better than nothing, but the scale of the map is too small to really see where the plants actually are. It would be much easier if we could look at the data interactively? 7.10 Interactive maps with leaflet We can generate interactive maps by calling the leaflet mapserver using wrapper functions in the leaflet R package written for this purpose. NOTE: If you can’t get leaflet to work it is probably a CRS problem. Your data need to be in Geographic or Web Mercator library(leaflet) library(htmltools) leaflet() %&gt;% # Add default OpenStreetMap map tiles addTiles(group = &quot;Default&quot;) %&gt;% # Add our points addCircleMarkers(data = pc, group = &quot;Protea cynaroides&quot;, radius = 3, color = &quot;green&quot;) Much better! Strange, but even though we filtered our iNaturalist records for captive_cultivated == \"false\" we still have a number of observations that appear to be in people’s gardens. Let this serve as a warning to be wary of all data! Always do “common-sense-checks” on your data and the outputs of your analyses!!! 7.11 Reprojecting One way to drastically reduce the number of cultivated records is to overlay the localities (points) with the remaining extent of the vegetation types (i.e. anything that is not in natural vegtation is likely to be cultivated). Let’s try that… #Get the remnants layer vegr &lt;- st_read(&quot;data/cape_peninsula/veg/Vegetation_Indigenous_Remnants.shp&quot;) ## Reading layer `Vegetation_Indigenous_Remnants&#39; from data source `/home/jasper/GIT/spatial-r/data/cape_peninsula/veg/Vegetation_Indigenous_Remnants.shp&#39; using driver `ESRI Shapefile&#39; ## Simple feature collection with 3428 features and 7 fields ## Geometry type: POLYGON ## Dimension: XY ## Bounding box: xmin: -63951.23 ymin: -3803532 xmax: 420.7595 ymax: -3705506 ## proj4string: +proj=tmerc +lat_0=0 +lon_0=19 +k=1 +x_0=0 +y_0=0 +ellps=WGS84 +units=m +no_defs hmm &lt;- st_intersection(pc, vegr) ## Error in geos_op2_geom(&quot;intersection&quot;, x, y): st_crs(x) == st_crs(y) is not TRUE Oops! The Coordinate Reference Systems are different! We will need to reproject one of the two datasets… Let’s see what CRS are currently set: st_crs(pc) ## Coordinate Reference System: ## User input: EPSG:4326 ## wkt: ## GEOGCS[&quot;WGS 84&quot;, ## DATUM[&quot;WGS_1984&quot;, ## SPHEROID[&quot;WGS 84&quot;,6378137,298.257223563, ## AUTHORITY[&quot;EPSG&quot;,&quot;7030&quot;]], ## AUTHORITY[&quot;EPSG&quot;,&quot;6326&quot;]], ## PRIMEM[&quot;Greenwich&quot;,0, ## AUTHORITY[&quot;EPSG&quot;,&quot;8901&quot;]], ## UNIT[&quot;degree&quot;,0.0174532925199433, ## AUTHORITY[&quot;EPSG&quot;,&quot;9122&quot;]], ## AUTHORITY[&quot;EPSG&quot;,&quot;4326&quot;]] So the points are Geographic. Besides having set it ourselves earlier, we know this because it indicates that the unit is degrees. st_crs(vegr) ## Coordinate Reference System: ## No user input ## wkt: ## PROJCS[&quot;WGS_1984_Transverse_Mercator&quot;, ## GEOGCS[&quot;GCS_WGS_1984&quot;, ## DATUM[&quot;Hartebeesthoek94&quot;, ## SPHEROID[&quot;WGS_84&quot;,6378137.0,298.257223563]], ## PRIMEM[&quot;Greenwich&quot;,0.0], ## UNIT[&quot;Degree&quot;,0.0174532925199433], ## AUTHORITY[&quot;EPSG&quot;,&quot;4326&quot;]], ## PROJECTION[&quot;Transverse_Mercator&quot;], ## PARAMETER[&quot;False_Easting&quot;,0.0], ## PARAMETER[&quot;False_Northing&quot;,0.0], ## PARAMETER[&quot;Central_Meridian&quot;,19.0], ## PARAMETER[&quot;Scale_Factor&quot;,1.0], ## PARAMETER[&quot;Latitude_Of_Origin&quot;,0.0], ## UNIT[&quot;Meter&quot;,1.0]] The vegetation types are in Transverse Mercator Lo19, because it says “Transverse Mercator” and the “Central_Meridian” is set to 19. In this case, either CRS is fine for our purposes, but let’s stick with Transverse Mercator Lo19, because it’ll be useful later. For this we need to reproject the veg layer like so: pc &lt;- st_transform(pc, st_crs(vegr)) Note that I fed it the CRS from vegr. This guarantees that they’ll be the same, even if we misidentified what the actual CRS is… 7.12 Intersecting points and polygons …and now we can try to intersect the points and polygons again… First lets see how many rows and columns the point data before the intersection: #call the dimensions of pc dim(pc) ## [1] 560 35 And after the intersection? pc &lt;- st_intersection(pc, vegr) ## Warning: attribute variables are assumed to be ## spatially constant throughout all geometries dim(pc) ## [1] 520 42 Less rows, but more columns! Two things have happened: The attribute data from the polygons in vegr intersected by the points in pc have been added to the attribute table in pc! All points that do not intersect the polygons in vegr were dropped (i.e. those that were recorded outside the remaining extent of natural vegetation). Let’s have a look ggplot() + annotation_map_tile(type = &quot;osm&quot;, progress = &quot;none&quot;) + geom_sf(data=pc) Yup, the localities in suburbia are gone… The map is a bit bland though. How about we use our “new information” about which vegetation types the observations occur in to colour or label the points on the map? 7.13 Colour or label points First, let’s add colour: library(wesanderson) pal &lt;- wes_palette(&quot;Darjeeling1&quot;, 7, type = &quot;continuous&quot;) ggplot() + annotation_map_tile(type = &quot;osm&quot;, progress = &quot;none&quot;) + geom_sf(data=pc, aes(col = National_)) + scale_colour_manual(values = pal) Looks like almost all of them are in Peninsula Sandstone Fynbos… pc %&gt;% group_by(National_) %&gt;% summarise(n()) ## Simple feature collection with 7 features and 2 fields ## Geometry type: GEOMETRY ## Dimension: XY ## Bounding box: xmin: -61546.64 ymin: -3795374 xmax: -48812.79 ymax: -3755803 ## proj4string: +proj=tmerc +lat_0=0 +lon_0=19 +k=1 +x_0=0 +y_0=0 +ellps=WGS84 +units=m +no_defs ## # A tibble: 7 x 3 ## National_ `n()` geometry ## &lt;chr&gt; &lt;int&gt; &lt;GEOMETRY [m]&gt; ## 1 Cape Flats… 1 POINT (-52779.19 -3769867) ## 2 Hangklip S… 1 POINT (-52770.86 -3780207) ## 3 Peninsula … 2 MULTIPOINT ((-55988.28 -3… ## 4 Peninsula … 7 MULTIPOINT ((-53861.58 -3… ## 5 Peninsula … 504 MULTIPOINT ((-61546.64 -3… ## 6 Peninsula … 1 POINT (-55866.09 -3755803) ## 7 Southern A… 4 MULTIPOINT ((-53682.79 -3… Yup! Note the numbers in column n(). But I can’t see where the Hangklip Sand Fynbos record is, so let’s label that one with text using geom_sf_label(). hsf &lt;- pc %&gt;% filter(National_ == &quot;Hangklip Sand Fynbos&quot;) #find the locality ggplot() + annotation_map_tile(type = &quot;osm&quot;, progress = &quot;none&quot;) + geom_sf(data=pc, aes(col = National_)) + scale_colour_manual(values = pal) + geom_sf_label(data=hsf, aes(label = &quot;Here&quot;)) Aha! Note that you can specify that the label = setting points to a column in your dataset with names if you have lots of labels to add. 7.14 Buffering One issue here may be that all localities should be in Peninsula Sandstone Fynbos, but the vegetation type boundaries are wrong. After all, the transition or ecotone between two vegetation types is usually diffuse rather than a clear boundary, not to mention that the data may have been digitized at a very small scale, compromizing precision and accuracy. One way to check this is to buffer the points using st_buffer to see if they are within some distance (say 250m) of the boundary with Peninsula Sandstone Fynbos. #Find the localities that are not in Peninsula Sandstone Fynbos and add a 250m buffer npsf &lt;- pc %&gt;% filter(National_ != &quot;Peninsula Sandstone Fynbos&quot;) %&gt;% st_buffer(dist = 250) #NOTE that st_buffer() makes them polygons, because they now have area! npsf$geometry[1] #The first geometry in npsf ## Geometry set for 1 feature ## Geometry type: POLYGON ## Dimension: XY ## Bounding box: xmin: -53871.39 ymin: -3762418 xmax: -53371.39 ymax: -3761918 ## proj4string: +proj=tmerc +lat_0=0 +lon_0=19 +k=1 +x_0=0 +y_0=0 +ellps=WGS84 +units=m +no_defs ## POLYGON ((-53371.39 -3762168, -53371.73 -376218... #Get the number of unique iNaturalist record numbers length(unique(npsf$id)) ## [1] 16 #Intersect new polygons with veg remnants and filter for those that overlap Peninsula Sandstone Fynbos only npsf &lt;- st_intersection(npsf, vegr) %&gt;% filter(National_.1 == &quot;Peninsula Sandstone Fynbos&quot;) ## Warning: attribute variables are assumed to be ## spatially constant throughout all geometries #Get the number of unique iNaturalist record numbers that overlap PSF length(unique(npsf$id)) ## [1] 7 So 7 of 16 records are suspiciously close to Peninsula Sandstone Fynbos… 7.15 Within distance and intersect Perhaps a more interesting use of buffering is to see if a species is within a certain distance of a particular habitat etc. For example, we could ask if a species is associated with riparian zones by buffering either the localities (points) or rivers (lines) and then doing an intersection. But of course there are many ways to skin a cat, and it turns out buffering and intersecting may not be the most efficient here. If we don’t want to pull the attribute data from one dataset to the other we can just use st_intersects() to see if they overlap at all. We can even take it one step further, because sf has the function st_is_within_distance(), which is similar to applying st_buffer() and st_intersects() in one go. Here we’ll use Brabejum stellatifolium (a riparian tree) as our focal species and the watercourse layer from the City of Cape Town. #Get the watercourse data water &lt;- st_read(&quot;data/cape_peninsula/Open_Watercourses.geojson&quot;) ## Reading layer `Open_Watercourses&#39; from data source `/home/jasper/GIT/spatial-r/data/cape_peninsula/Open_Watercourses.geojson&#39; using driver `GeoJSON&#39; ## Simple feature collection with 10848 features and 11 fields ## Geometry type: MULTILINESTRING ## Dimension: XY ## Bounding box: xmin: 18.31249 ymin: -34.28774 xmax: 18.99045 ymax: -33.47256 ## CRS: 4326 #Check it&#39;s CRS st_crs(water) ## Coordinate Reference System: ## User input: 4326 ## wkt: ## GEOGCS[&quot;WGS 84&quot;, ## DATUM[&quot;WGS_1984&quot;, ## SPHEROID[&quot;WGS 84&quot;,6378137,298.257223563, ## AUTHORITY[&quot;EPSG&quot;,&quot;7030&quot;]], ## AUTHORITY[&quot;EPSG&quot;,&quot;6326&quot;]], ## PRIMEM[&quot;Greenwich&quot;,0, ## AUTHORITY[&quot;EPSG&quot;,&quot;8901&quot;]], ## UNIT[&quot;degree&quot;,0.0174532925199433, ## AUTHORITY[&quot;EPSG&quot;,&quot;9122&quot;]], ## AUTHORITY[&quot;EPSG&quot;,&quot;4326&quot;]] #Call the data directly from iNat bs &lt;- get_inat_obs(taxon_name = &quot;Brabejum stellatifolium&quot;, bounds = c(-35, 18, -33.5, 18.5), maxresults = 1000) #Filter returned observations by a range of attribute criteria bs &lt;- bs %&gt;% filter(positional_accuracy&lt;46 &amp; latitude&lt;0 &amp; !is.na(latitude) &amp; captive_cultivated == &quot;false&quot; &amp; quality_grade == &quot;research&quot;) #Make the dataframe a spatial object of class = &quot;sf&quot; bs &lt;- st_as_sf(bs, coords = c(&quot;longitude&quot;, &quot;latitude&quot;), crs = 4326) #Note that I had to define the CRS (as Geographic WGS84)!!! Let’s see what we’ve got… #Crop the water courses to the extent of the locality data water &lt;- st_crop(water, bs) ## although coordinates are longitude/latitude, st_intersection assumes that they are planar ## Warning: attribute variables are assumed to be ## spatially constant throughout all geometries #Plot ggplot() + annotation_map_tile(type = &quot;osm&quot;, progress = &quot;none&quot;) + geom_sf(data = water, colour = &quot;blue&quot;) + geom_sf(data=bs) Hard to tell, but they could all be on rivers? Let’s try st_intersects() without any buffering first to see if they overlap at all. st_intersects(bs, water) %&gt;% unlist() ## although coordinates are longitude/latitude, st_intersects assumes that they are planar ## integer(0) Oops! We forgot to project our data! bs &lt;- st_transform(bs, st_crs(vegr)) water &lt;- st_transform(water, st_crs(vegr)) st_intersects(bs, water) %&gt;% unlist() ## integer(0) So none of them intersect, but this is not surprising, because lines and points in GIS do not have area, so they can’t really intersect unless you buffer them… Let’s try st_is_within_distance() and set it for 20 metres. Note that I add unlist() %&gt;% unique() because the function returns a list and will return the same feature (line/river) multiple times - once for every point (tree) it is within 20m of. st_is_within_distance(bs, water, 20) %&gt;% unlist() %&gt;% unique() ## [1] 328 327 346 885 351 179 349 294 285 333 ## [11] 332 330 101 224 280 281 282 615 19 So it’s given us the list of lines (rivers) within 20m of our points, but that doesn’t tell us how many (or what proportion) of our points are within 20m of a river. Let’s apply the function again, swapping the layers around: st_is_within_distance(water, bs, 20) %&gt;% unlist() %&gt;% unique() ## [1] 123 108 124 134 47 67 76 84 61 62 ## [11] 3 32 33 101 102 2 17 51 53 116 ## [21] 100 86 27 48 49 77 50 45 44 46 ## [31] 57 112 So only ~30 of the trees are within 20m of the rivers. What about 50m? st_is_within_distance(water, bs, 100) %&gt;% unlist() %&gt;% unique() ## [1] 65 123 108 124 134 5 21 89 115 47 ## [11] 67 76 1 30 52 68 70 71 72 80 ## [21] 84 88 96 99 125 79 103 126 69 97 ## [31] 98 61 62 29 13 107 54 2 3 7 ## [41] 9 10 14 17 32 33 39 40 41 42 ## [51] 43 59 64 74 85 91 93 94 95 101 ## [61] 102 116 118 129 12 19 20 34 35 36 ## [71] 37 38 51 53 66 100 86 27 48 49 ## [81] 77 87 130 50 45 127 44 46 57 112 ## [91] 63 So about 90… It’s at this point that it’s worth thinking about the scale, precision and accuracy of both the species localities and the watercourse data before drawing any strong conclusions!!! "],["raster-gis-operations-in-r.html", "8 Raster GIS operations in R 8.1 Reading in data 8.2 Cropping 8.3 Aggregating / Resampling 8.4 Basic plotting 8.5 Disaggregating 8.6 Raster maths! 8.7 Terrain calculations 8.8 Raster stacks 8.9 Extracting raster to vector 8.10 Rasterizing", " 8 Raster GIS operations in R 8.1 Reading in data Ok, now to look at handling rasters. As with sf, the raster package has one function (raster()) that can read in just about any raster file format. Let’s get started and read in the digital elevation model (DEM) for the City of Cape Town. dem &lt;- raster(&quot;/home/jasper/Documents/Datasets/CoCT/10m_Grid_GeoTiff/10m_BA.tif&quot;) class(dem) ## [1] &quot;RasterLayer&quot; ## attr(,&quot;package&quot;) ## [1] &quot;raster&quot; dem #Typing the name of a &quot;raster&quot; class data object gives you the details ## class : RasterLayer ## dimensions : 9902, 6518, 64541236 (nrow, ncol, ncell) ## resolution : 10, 10 (x, y) ## extent : -64180, 1000, -3804020, -3705000 (xmin, xmax, ymin, ymax) ## crs : +proj=tmerc +lat_0=0 +lon_0=19 +k=1 +x_0=0 +y_0=0 +datum=WGS84 +units=m +no_defs +ellps=WGS84 +towgs84=0,0,0 ## source : /home/jasper/Documents/Datasets/CoCT/10m_Grid_GeoTiff/10m_BA.tif ## names : X10m_BA ## values : -32768, 32767 (min, max) From the proj4string we can see that the coordinate reference system is Transverse Mercator Lo19. If you just want to know the CRS from a raster, you just call the proj4string like so: proj4string(dem) ## [1] &quot;+proj=tmerc +lat_0=0 +lon_0=19 +k=1 +x_0=0 +y_0=0 +datum=WGS84 +units=m +no_defs +ellps=WGS84 +towgs84=0,0,0&quot; Similar to st_crs(), you can define a projection using the syntax proj4string(your_raster) &lt;- \"your_proj4string\". For reprojecting, you use the function projectRaster(). We’ll look at it later. 8.2 Cropping Ok, before we try to anything with this dataset, let’s think about how big it is… One of the outputs of calling dem was the row reading dimensions : 9902, 6518, 64541236 (nrow, ncol, ncell). Given that we are talking about 10m pixels, this information tells us that the extent of the region is roughly 100km by 65km and that there are ~65 million pixels! No wonder the file is ~130MB. While R can handle this, it will be slow! There are many ways to improve the efficiency of handling big rasters in R (see this post for details if you’re interested), but for the purposes of this tutorial we’re going to take the easy option and just crop it to a smaller extent, like so: dem &lt;- crop(dem, extent(c(-66642.18, -44412.18, -3809853.29, -3750723.29))) Note that the crop() function requires us to pass it an object of class extent. Just like st_crop() from sf, crop() can derive the extent from another data object. One silly difference, is that if you pass it the coordinates of the extent manually (as above), you first need to pass it to the extent() function, and they need to follow the order xmin, xmax, ymin, ymax (as opposed to xmin, ymin, xmax, ymax as you do for st_crop()). Keep your eye out for these little differences, because they will trip you up… Ok, so how big is our dataset now? dem ## class : RasterLayer ## dimensions : 5330, 1977, 10537410 (nrow, ncol, ncell) ## resolution : 10, 10 (x, y) ## extent : -64180, -44410, -3804020, -3750720 (xmin, xmax, ymin, ymax) ## crs : +proj=tmerc +lat_0=0 +lon_0=19 +k=1 +x_0=0 +y_0=0 +datum=WGS84 +units=m +no_defs +ellps=WGS84 +towgs84=0,0,0 ## source : memory ## names : X10m_BA ## values : -15, 1084 (min, max) …still &gt;10 million pixels… 8.3 Aggregating / Resampling Do we need 10m data? If your analysis doesn’t need such fine resolution data, you can resample the raster to a larger pixel size, like 30m. The aggregate() function in the raster package does this very efficiently, like so: dem30 &lt;- aggregate(dem, fact = 3, fun = mean) Here I’ve told it to aggregate by a factor of 3 (i.e. bin 9 neighbouring pixels (3x3) into one) and to assign the bigger pixel the mean of the 9 original pixels. This obviously results in some data loss, but that can be acceptable, depending on the purpose of your analysis. Note that you can pass just about any function to fun =, like min(), max() or even your own function. dem30 ## class : RasterLayer ## dimensions : 1777, 659, 1171043 (nrow, ncol, ncell) ## resolution : 30, 30 (x, y) ## extent : -64180, -44410, -3804030, -3750720 (xmin, xmax, ymin, ymax) ## crs : +proj=tmerc +lat_0=0 +lon_0=19 +k=1 +x_0=0 +y_0=0 +datum=WGS84 +units=m +no_defs +ellps=WGS84 +towgs84=0,0,0 ## source : memory ## names : X10m_BA ## values : -15, 1083.556 (min, max) Ok, so we’ve reduced the size of the raster by a factor of 9 and only have a little over 1 million pixels to deal with. Much more reasonable! Now let’s have a look at what we’re dealing with. 8.4 Basic plotting Now that we’ve reduced the size of the dataset, we can try the base plotting function: plot(dem30) Or with the Tidyverse… But ggplot() doesn’t accept rasters, so we need it a dataframe with x and y columns for the coordinates, and a column containing the values to plot. This is easily done, firstly by converting the raster to a vector layer of points, and then by coorcing that into a dataframe, like so: #convert to points dem30df &lt;- rasterToPoints(dem30, spatial = TRUE) class(dem30df) #note that this is a class from library(sp) ## [1] &quot;SpatialPointsDataFrame&quot; ## attr(,&quot;package&quot;) ## [1] &quot;sp&quot; #coerce to a dataframe dem30df &lt;- data.frame(dem30df) names(dem30df) ## [1] &quot;X10m_BA&quot; &quot;x&quot; &quot;y&quot; ## [4] &quot;optional&quot; #call tidyverse libraries and plot library(tidyverse) dem30df %&gt;% ggplot() + geom_raster(aes(x = x, y = y, fill = X10m_BA)) Ok, how different does our 30m raster look to the 10m version? demdf &lt;- data.frame(rasterToPoints(dem, spatial = TRUE)) names(demdf) ## [1] &quot;X10m_BA&quot; &quot;x&quot; &quot;y&quot; ## [4] &quot;optional&quot; demdf %&gt;% ggplot() + geom_raster(aes(x = x, y = y, fill = X10m_BA)) Not noticeably different at this scale! 8.5 Disaggregating dem10 &lt;- disaggregate(dem30, fact = 3, method = &quot;bilinear&quot;) One way to explore the degree of data loss is to disaggregate() our 30m DEM back to 10m and then compare it to the original. Note that I’ve tried to use bilinear interpolation to give it a fair chance of getting nearer the original values. Now, how can I compare my two 10m rasters? 8.6 Raster maths! The raster package makes this easy, because you can do maths with rasters, treating tham as variables in an equation. So we can calculate the data loss as the difference between the original and disaggregated DEMS, like so. diff &lt;- dem - dem10 ## Warning in dem - dem10: Raster objects ## have different extents. Result for their ## intersection is returned Note that the error is because we lost some of the 10m cells along the edged when we aggregated… diffdf &lt;- data.frame(rasterToPoints(diff, spatial = TRUE)) names(diffdf) ## [1] &quot;layer&quot; &quot;x&quot; &quot;y&quot; ## [4] &quot;optional&quot; diffdf %&gt;% ggplot() + geom_raster(aes(x = x, y = y, fill = layer)) If you look really closely, you’ll see the outline of the cliffs of Table Mountain, where you’d expect the data loss to be worst. The colour ramp tells us that the worst distortion was up to 100m, or about 10% of the elevation range in this dataset, but don’t be fooled by the extremes! Let’s have a look at all the values as a histogram. diffdf %&gt;% ggplot() + geom_histogram(aes(layer)) ## `stat_bin()` using `bins = 30`. Pick better ## value with `binwidth`. Looks like most values are within 10 or so metres of their original values, so the data loss really wasn’t that bad! 8.7 Terrain calculations In addition to raster maths with multiple rasters, you can do all kinds of calculations within a raster using focal(). This essentially applies a moving window, calculating values for a neighbourhood of cells using whatever function you supplied (mean, max, your own, etc) as it goes. The function terrain() is a special case of focal() optimized for calculating slope, aspect, topographic position index (TPI), topographic roughness index (TRI), roughness, or flow direction. Here I’ll calculate the slope and aspect so that we can pass them to the function hillShade() to make a pretty hillshade layer. aspect &lt;- terrain(dem30, &quot;aspect&quot;) slope &lt;- terrain(dem30, &quot;slope&quot;) hillshade &lt;- hillShade(slope, aspect) plot(hillshade) Probably prettier with Tidyverse: hsdf &lt;- data.frame(rasterToPoints(hillshade, spatial = TRUE)) names(hsdf) ## [1] &quot;layer&quot; &quot;x&quot; &quot;y&quot; ## [4] &quot;optional&quot; hsdf %&gt;% ggplot() + geom_raster(aes(x = x, y = y, fill = layer)) + scale_fill_gradient(low = &quot;grey10&quot;, high = &quot;grey90&quot;) 8.8 Raster stacks A nice thing about rasters is that if you have multiple rasters “on the same grid” (i.e. with the same pixel size, extent and CRS) then you can stack them and work with them as a single rasterstack object. dstack &lt;- stack(dem30, slope, aspect, hillshade) dstack ## class : RasterStack ## dimensions : 1777, 659, 1171043, 4 (nrow, ncol, ncell, nlayers) ## resolution : 30, 30 (x, y) ## extent : -64180, -44410, -3804030, -3750720 (xmin, xmax, ymin, ymax) ## crs : +proj=tmerc +lat_0=0 +lon_0=19 +k=1 +x_0=0 +y_0=0 +datum=WGS84 +units=m +no_defs +ellps=WGS84 +towgs84=0,0,0 ## names : X10m_BA, slope, aspect, layer ## min values : -15.0000000, 0.0000000, 0.0000000, -0.4906481 ## max values : 1083.5555556, 1.3708258, 6.2831853, 0.9999974 As you can see the “dimensions” now report 4 layers, and there are 4 names. Some of these don’t look all that informative though, so let’s rename them. names(dstack) &lt;- c(&quot;elevation&quot;, &quot;slope&quot;, &quot;aspect&quot;, &quot;shade&quot;) 8.9 Extracting raster to vector Ok, enough fooling around. More often than not, we just want to extract data from rasters for further analyses (e.g. climate layers, etc), so let’s cover that base here. Extract to points First, let’s get some points for two species in the Proteaceae, Protea cynaroides and Leucospermum conocarpodendron… library(rinat) #Call data for two species directly from iNat pc &lt;- get_inat_obs(taxon_name = &quot;Protea cynaroides&quot;, bounds = c(-35, 18, -33.5, 18.5), maxresults = 1000) ll &lt;- get_inat_obs(taxon_name = &quot;Leucadendron laureolum&quot;, bounds = c(-35, 18, -33.5, 18.5), maxresults = 1000) #Combine the records into one dataframe pc &lt;- rbind(pc,ll) #Filter returned observations by a range of attribute criteria pc &lt;- pc %&gt;% filter(positional_accuracy&lt;46 &amp; latitude&lt;0 &amp; !is.na(latitude) &amp; captive_cultivated == &quot;false&quot; &amp; quality_grade == &quot;research&quot;) #Make the dataframe a spatial object of class = &quot;sf&quot; pc &lt;- st_as_sf(pc, coords = c(&quot;longitude&quot;, &quot;latitude&quot;), crs = 4326) Now let’s extract the data to the points. dat &lt;- extract(dem30, pc) ## Warning in .local(x, y, ...): Transforming ## SpatialPoints to the CRS of the Raster Note how raster conveniently handled my oversight about making sure the CRS are the same for both layers! head(dat) ## [1] 704.5556 462.0000 516.4444 454.3333 ## [5] 456.7778 701.0000 Hmm… ok… It just returned the vector of numbers… not all that handy on it’s own. Let’s add it to out points layer and plot. pc$dem30 &lt;- dat pc %&gt;% ggplot() + geom_boxplot(aes(scientific_name, dem30)) (Hmm… do you think those Leucadendron laureolum outliers could actually be Leucadendron strobilinum?) Nice! But what if we have data lots of rasters? #extract from stack dat &lt;- extract(dstack, pc) ## Warning in .local(x, y, ...): Transforming ## SpatialPoints to the CRS of the Raster #bind columns to points edat &lt;- cbind(as.data.frame(pc), dat) #select columns we want and tidy data into long format edat &lt;- edat %&gt;% as_tibble() %&gt;% dplyr::select(scientific_name, elevation, slope, aspect, shade) %&gt;% pivot_longer(c(elevation, slope, aspect, shade)) #panel boxplot of the variables extracted edat %&gt;% ggplot() + geom_boxplot(aes(scientific_name, value)) + facet_wrap(~name, scales = &quot;free&quot;) Something I should have mentioned is that if you would like each point to sample a larger region you can add a buffer = argument to the extract() function, and a function (fun =) to summarize the neighbourhood of pixels sampled, like so: pc$dem30 &lt;- extract(dem30, pc, buffer = 200, fun = mean) ## Warning in .local(x, y, ...): Transforming ## SpatialPoints to the CRS of the Raster pc %&gt;% ggplot() + geom_boxplot(aes(scientific_name, dem30)) Extract to polygons binning 8.10 Rasterizing We could even add contours… ggplot() + geom_raster(data = hsdf, aes(x = x, y = y, fill = layer, alpha = 0.5)) + scale_fill_gradient(low = &quot;grey10&quot;, high = &quot;grey90&quot;) + geom_contour(data = dem30df, aes(x = x, y = y, z = X10m_BA), breaks = seq(0, 1100, 100), colour = &quot;black&quot;) + theme(legend.position = &quot;none&quot;) "],["references.html", "References", " References Mucina, Ladislav, Michael C Rutherford, and Others. 2006. The vegetation of South Africa, Lesotho and Swaziland. South African National Biodiversity Institute. Skowno, Andrew L, Debbie Jewitt, and Jasper A Slingsby. 2021. “Rates and patterns of habitat loss across South Africa’s vegetation biomes.” South African Journal of Science 117 (1/2). https://doi.org/10.17159/sajs.2021/8182. "]]
