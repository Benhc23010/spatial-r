---
  bookdown::gitbook:
    config:
      toc:
        collapse: null
      edit: null
      download: null
---

# Raster GIS operations in R

## Reading in data

Ok, now to look at handling rasters. As with _sf_, the _raster_ package has one function (`raster()`) that can read in just about any raster file format. Let's get started and read in the digital elevation model (DEM) for the City of Cape Town.

```{r}
dem <- raster("/home/jasper/Documents/Datasets/CoCT/10m_Grid_GeoTiff/10m_BA.tif")

class(dem)

dem #Typing the name of a "raster" class data object gives you the details
```

From the _proj4string_ we can see that the coordinate reference system is Transverse Mercator Lo19. If you just want to know the CRS from a raster, you just call the _proj4string_ like so:

```{r}
proj4string(dem)
```

Similar to `st_crs()`, you can define a projection using the syntax `proj4string(your_raster) <- "your_proj4string"`. For reprojecting, you use the function `projectRaster()`. We'll look at it later.

<br>

## Cropping

Ok, before we try to anything with this dataset, let's think about how big it is... One of the outputs of calling `dem` was the row reading `dimensions : 9902, 6518, 64541236  (nrow, ncol, ncell)`. Given that we are talking about 10m pixels, this information tells us that the extent of the region is roughly 100km by 65km and that there are ~65 million pixels! No wonder the file is ~130MB. While R can handle this, it will be slow! There are many ways to improve the efficiency of handling big rasters in R (see [this post for details](https://www.ecologi.st/post/big-spatial-data/) if you're interested), but for the purposes of this tutorial we're going to take the easy option and just crop it to a smaller extent, like so:

```{r}
dem <- crop(dem, extent(c(-66642.18, -44412.18, -3809853.29, -3750723.29)))
```

Note that the `crop()` function requires us to pass it an object of class `extent`. Just like `st_crop()` from _sf_, `crop()` can derive the extent from another data object. One silly difference, is that if you pass it the coordinates of the extent manually (as above), you first need to pass it to the `extent()` function, and they need to follow the order _xmin, xmax, ymin, ymax_ (as opposed to _xmin, ymin, xmax, ymax_ as you do for `st_crop()`). Keep your eye out for these little differences, because they will trip you up...

Ok, so how big is our dataset now?

```{r}
dem
```

...still >10 million pixels...

<br>

## Aggregating / Resampling

Do we need 10m data? If your analysis doesn't need such fine resolution data, you can resample the raster to a larger pixel size, like 30m. The `aggregate()` function in the _raster_ package does this very efficiently, like so:

```{r}
dem30 <- aggregate(dem, fact = 3, fun = mean)
```

Here I've told it to aggregate by a factor of 3 (i.e. bin 9 neighbouring pixels (3x3) into one) and to assign the bigger pixel the mean of the 9 original pixels. This obviously results in some data loss, but that can be acceptable, depending on the purpose of your analysis. Note that you can pass just about any function to `fun =`, like `min()`, `max()` or even your own function.

```{r}
dem30
```

Ok, so we've reduced the size of the raster by a factor of 9 and only have a little over 1 million pixels to deal with. Much more reasonable! Now let's have a look at what we're dealing with.

<br>

## Basic plotting

Now that we've reduced the size of the dataset, we can try the base plotting function:

```{r}
plot(dem30)
```

Or with the _Tidyverse_...

But `ggplot()` doesn't accept rasters, so we need it a dataframe with _x_ and _y_ columns for the coordinates, and a column containing the values to plot. This is easily done, firstly by converting the raster to a vector layer of points, and then by coorcing that into a dataframe, like so:

```{r, fig.width=3.5}
#convert to points
dem30df <- rasterToPoints(dem30, spatial = TRUE)

class(dem30df) #note that this is a class from library(sp)

#coerce to a dataframe
dem30df <- data.frame(dem30df)

names(dem30df)

#call tidyverse libraries and plot
library(tidyverse)

dem30df %>%
  ggplot() +
  geom_raster(aes(x = x, y = y, fill = X10m_BA))
```

Ok, how different does our 30m raster look to the 10m version?

```{r, fig.width=3.5}
demdf <- data.frame(rasterToPoints(dem, spatial = TRUE))

names(demdf)

demdf %>%
  ggplot() +
  geom_raster(aes(x = x, y = y, fill = X10m_BA))
```

Not noticeably different at this scale!

<br>

## Disaggregating

```{r}
dem10 <- disaggregate(dem30, fact = 3, method = "bilinear")
```

One way to explore the degree of data loss is to `disaggregate()` our 30m DEM back to 10m and then compare it to the original.

Note that I've tried to use _bilinear interpolation_ to give it a fair chance of getting nearer the original values.

Now, how can I compare my two 10m rasters?

<br>

## Raster maths!

The _raster_ package makes this easy, because you can do maths with rasters, treating tham as variables in an equation. So we can calculate the data loss as the difference between the original and disaggregated DEMS, like so.

```{r}
diff <- dem - dem10
```

Note that the error is because we lost some of the 10m cells along the edged when we aggregated...

```{r, fig.width=3.5}
diffdf <- data.frame(rasterToPoints(diff, spatial = TRUE))

names(diffdf)

diffdf %>%
  ggplot() +
  geom_raster(aes(x = x, y = y, fill = layer))
```

If you look _really_ closely, you'll see the outline of the cliffs of Table Mountain, where you'd expect the data loss to be worst. The colour ramp tells us that the worst distortion was up to 100m, or about 10% of the elevation range in this dataset, but don't be fooled by the extremes! Let's have a look at all the values as a histogram.

```{r}
diffdf %>%
  ggplot() +
  geom_histogram(aes(layer))
```

Looks like most values are within 10 or so metres of their original values, so the data loss really wasn't that bad!

<br>

## Terrain calculations

In addition to raster maths with multiple rasters, you can do all kinds of calculations within a raster using `focal()`. This essentially applies a moving window, calculating values for a neighbourhood of cells using whatever function you supplied (mean, max, your own, etc) as it goes. 

The function `terrain()` is a special case of `focal()` optimized for calculating _slope, aspect, topographic position index (TPI), topographic roughness index (TRI), roughness, or flow direction_.

Here I'll calculate the slope and aspect so that we can pass them to the function `hillShade()` to make a pretty hillshade layer.

```{r}
aspect <- terrain(dem30, "aspect")

slope <- terrain(dem30, "slope")

hillshade <- hillShade(slope, aspect)

plot(hillshade)
```

Probably prettier with _Tidyverse_:

```{r, fig.width=3.5}
hsdf <- data.frame(rasterToPoints(hillshade, spatial = TRUE))

names(hsdf)

hsdf %>%
  ggplot() +
  geom_raster(aes(x = x, y = y, fill = layer)) +
  scale_fill_gradient(low = "grey10", high = "grey90")
```

## Raster stacks

A nice thing about rasters is that if you have multiple rasters "on the same grid" (i.e. with the same pixel size, extent and CRS) then you can _stack_ them and work with them as a single _rasterstack_ object.

```{r}
dstack <- stack(dem30, slope, aspect, hillshade)

dstack
```

As you can see the "dimensions" now report 4 layers, and there are 4 names. Some of these don't look all that informative though, so let's rename them.

```{r}
names(dstack) <- c("elevation", "slope", "aspect", "shade")
```


<br>

## Extracting raster to vector

Ok, enough fooling around. More often than not, we just want to extract data from rasters for further analyses (e.g. climate layers, etc), so let's cover that base here.

<br>

**Extract to points**

First, let's get some points for two species in the Proteaceae, _Protea cynaroides_ and _Leucospermum conocarpodendron_...

```{r}
library(rinat)

#Call data for two species directly from iNat
pc <- get_inat_obs(taxon_name = "Protea cynaroides",
                   bounds = c(-35, 18, -33.5, 18.5),
                   maxresults = 1000)

ll <- get_inat_obs(taxon_name = "Leucadendron laureolum",
                   bounds = c(-35, 18, -33.5, 18.5),
                   maxresults = 1000)

#Combine the records into one dataframe
pc <- rbind(pc,ll)

#Filter returned observations by a range of attribute criteria
pc <- pc %>% filter(positional_accuracy<46 & 
                latitude<0 &
                !is.na(latitude) &
                captive_cultivated == "false" &
                quality_grade == "research")

#Make the dataframe a spatial object of class = "sf"
pc <- st_as_sf(pc, coords = c("longitude", "latitude"), crs = 4326)
```

Now let's extract the data to the points.

```{r}
dat <- extract(dem30, pc)
```

Note how _raster_ conveniently handled my oversight about making sure the CRS are the same for both layers!

```{r}
head(dat)
```

Hmm... ok... It just returned the vector of numbers... not all that handy on it's own. Let's add it to out points layer and plot.

```{r}
pc$dem30 <- dat

pc %>% ggplot() +
  geom_boxplot(aes(scientific_name, dem30))
```

(Hmm... do you think those _Leucadendron laureolum_ outliers could actually be _Leucadendron strobilinum_?)

Nice! But what if we have data lots of rasters?

```{r}
#extract from stack
dat <- extract(dstack, pc) 

#bind columns to points
edat <- cbind(as.data.frame(pc), dat)

#select columns we want and tidy data into long format
edat <- edat %>% 
  as_tibble() %>% 
  dplyr::select(scientific_name, elevation, slope, aspect, shade) %>% 
  pivot_longer(c(elevation, slope, aspect, shade))

#panel boxplot of the variables extracted
edat %>% ggplot() +
  geom_boxplot(aes(scientific_name, value)) +
  facet_wrap(~name, scales = "free") 
```

<br>

Something I should have mentioned is that if you would like each point to sample a larger region you can add a `buffer =` argument to the `extract()` function, and a function (`fun =`) to summarize the neighbourhood of pixels sampled, like so:

```{r}
pc$dem30 <- extract(dem30, pc, buffer = 200, fun = mean)

pc %>% ggplot() +
  geom_boxplot(aes(scientific_name, dem30))
```

**Extract to polygons**



- binning

<br>

## Rasterizing



We could even add contours...

```{r, fig.width=3.5}
  ggplot() +
  geom_raster(data = hsdf, aes(x = x, y = y, fill = layer, alpha = 0.5)) +
  scale_fill_gradient(low = "grey10", high = "grey90") +
  geom_contour(data = dem30df, aes(x = x, y = y, z = X10m_BA), breaks = seq(0, 1100, 100), colour = "black") +
  theme(legend.position = "none")
```
